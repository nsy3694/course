{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绪论\n",
    "## 为什么需要数据挖掘技术\n",
    "数据量过大，异构数据和复杂数据等原因导致已经无法使用传统的分析工具和技术来发现隐藏在数据里的知识。\n",
    "##  什么是数据挖掘(Data Mining)\n",
    "数据挖掘是将未加工的数据转换为有用信息的整个过程，如下图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T06:23:30.746050Z",
     "start_time": "2020-12-21T06:23:30.741232Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./kdd_process.png\", width=1320, heigth=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./kdd_process.png\", width=1320, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据挖掘的任务\n",
    "通常数据挖掘任务分为两大类\n",
    "+ **预测任务**。这些任务的目标是根据其他属性的值，预测特定属性的值（分类、回归、目标检测、实体分割、语义分割等）。被预测的属性一般称为**目标变量（target variable）** 或 **因变量**。而用来预测的属性一般称为**特征变量（feature variable）** 或 **自变量**。\n",
    "+ **描述任务**。其目标是导出概括数据中潜在的普遍模式（关联分析、趋势、聚类、异常检测等）。  \n",
    " \n",
    " \n",
    "几种主要的数据挖掘任务如下图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T07:08:57.949571Z",
     "start_time": "2020-12-21T07:08:57.940471Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./dm_task.png\", width=700, heigth=500>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./dm_task.png\", width=700, heigth=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预测建模**涉及以特征变量函数的方式为目标变量建立模型，**分类（classification）** 用于预测离散的目标变量，**回归（regression）** 用于预测连续的目标变量。例如预测用户是否会购买某件商品、图片中的物体是猫还是狗还是人，一条评论是积极的还是消极的是分类任务，因为预测的变量是二值或有限个多值。预测某个门店中的商品销量，一家上市公司的未来一年的盈利是回归任务，因为销量、利润具有连续值属性，两项任务目标都是训练一个模型，使目标变量预测值与实际值之间的误差达到最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测花的类型\n",
    "考虑如下任务：根据花的特征预测花的种类。根据鸢尾花（iris）的四个特征,花萼的长度、宽度以及花瓣的长度、宽度预测花属于Setosa、Versicolour、Virginica这三类中的哪一类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:42:13.808902Z",
     "start_time": "2020-12-21T08:42:13.789559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          5.1         3.5          1.4         0.2        0\n",
       "1          4.9         3.0          1.4         0.2        0\n",
       "2          4.7         3.2          1.3         0.2        0\n",
       "3          4.6         3.1          1.5         0.2        0\n",
       "4          5.0         3.6          1.4         0.2        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据挖掘所需要的主要技术\n",
    "+ 数学理论 ：微积分、矩阵分析、概率论等。 \n",
    "+ 数据处理和分析：常用的数据处理方法和传统分析方法。 \n",
    "+ 算法：常用机器学习算法、深度学习算法。 \n",
    "+ 其他领域思想：最优化、信息论、信号处理、可视化、信息检索等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表格数据集  \n",
    "**数据集**：数据集通常是由数据构成的一个矩形数组（多维数组ndarray、矩阵matrix、数据框dataframe），行表示观测(样本)，列表示变量（特征）。  \n",
    "**数据类型**：连续型和离散型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:42:22.159760Z",
     "start_time": "2020-12-21T08:42:22.134342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0            5.1         3.5          1.4         0.2        0\n",
       "1            4.9         3.0          1.4         0.2        0\n",
       "2            4.7         3.2          1.3         0.2        0\n",
       "3            4.6         3.1          1.5         0.2        0\n",
       "4            5.0         3.6          1.4         0.2        0\n",
       "..           ...         ...          ...         ...      ...\n",
       "145          6.7         3.0          5.2         2.3        2\n",
       "146          6.3         2.5          5.0         1.9        2\n",
       "147          6.5         3.0          5.2         2.0        2\n",
       "148          6.2         3.4          5.4         2.3        2\n",
       "149          5.9         3.0          5.1         1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:43:08.426592Z",
     "start_time": "2020-12-21T08:43:08.297167Z"
    }
   },
   "source": [
    "多维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:42:31.524890Z",
     "start_time": "2020-12-21T08:42:31.503273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集 验证集 测试集(train validation test dataset)\n",
    "+ 训练集（train set） —— 用于模型拟合的数据样本。 \n",
    "\n",
    "+ 验证集（validation/development set）—— 是模型训练过程中单独留出的样本集，它可以用于调整模型的超参数和用于对模型的能力进行初步评估，也可以使用交叉验证（cross validation）的方式。 \n",
    "\n",
    "+ 测试集 —— 用来评估模最终模型的泛化能力。但不能作为调参、选择特征等算法相关的选择的依据。\n",
    "\n",
    "为什么要这样划分？\n",
    "\n",
    "训练集直接参与了模型调参的过程，显然不能用来反映模型真实的能力（会过拟合)。\n",
    "\n",
    "验证集参与了人工调参(超参数)的过程，也不能用来最终评判一个模型。\n",
    "\n",
    "所以要通过最终的测试集来考察一个模型真正的能力。\n",
    "\n",
    "### 过拟合问题（THE PROBLEM OF OVERFITTING） \n",
    "如果我们有非常多的特征，我们通过学习得到的假设可能能够非常好地适应训练集（损失函数可能几乎为 0），但是可能会不能推广到新的数据。 \n",
    "\n",
    "下图是一个回归问题的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:42:36.514831Z",
     "start_time": "2020-12-24T05:42:36.506177Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./overfitting.png\", width=600, heigth=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./overfitting.png\", width=600, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类问题中也存在这样的问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:44:42.047806Z",
     "start_time": "2020-12-24T05:44:42.038906Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./overfitting_1.png\", width=600, heigth=600>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./overfitting_1.png\", width=600, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T09:40:22.587282Z",
     "start_time": "2020-12-24T09:40:22.583760Z"
    }
   },
   "source": [
    "过拟合问题：train低偏差，valid高方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**机器学习领域的重要假设** ：独立同分布IID(independent and identically distributed) \n",
    "\n",
    "即假设训练数据和测试数据是满足相同分布的，它是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。\n",
    "独立同分布假设并不是必须的。但独立同分布的数据可以简化常规机器学习模型的训练、提升机器学习模型的预测能力，已经是一个共识。\n",
    "Internal Covariate Shift 问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 描述性统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习\n",
    "## 什么是机器学习(Machine Learning)\n",
    "比较现代且形式化的定义是由 Tom Mitchell 在 1998 年给出的：\n",
    "对于某个任务 T 和表现的衡量 P，当计算机程序在该任务 T 的表现上，经过 P 的衡量，随着经验 E 而增长，我们便称计算机程序能够通过经验 E 来学习该任务。 \n",
    "举例来说：编写了一个下棋游戏的程序，并且让这个程序和程序自身玩了几万局棋游戏，并且记录下来棋盘上的什么位置可能会导致怎样的结果，随着时间的推移，计算机学会了棋盘上的哪些位置可能会导致胜利，并且最终战胜了程序设计者。在下棋游戏的例子中，任务 T 是玩下棋游戏，P 是游戏的输赢，E 则是一局又一局的游戏。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习和非监督学习\n",
    "### 监督学习（Supervised Learning）\n",
    "假设你有下面这些房价数据，图表上的每个实例都是一次房屋交易，横坐标为交易房屋的占地面积，纵坐标为房屋的交易价格。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T03:08:55.218897Z",
     "start_time": "2020-12-23T03:08:55.210690Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./house_price_prediction.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./house_price_prediction.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，假设你希望能够预测一个 750 平方英尺的房屋的交易价格可能是多少。一种方法是根据这些数据点的分布，画一条合适的直线，然后根据这条直线来预测。在房价预测这个例子中，一个二次函数可能更适合已有的数据，我们可能会更希望用这个二次函数的曲线来进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T03:13:35.171322Z",
     "start_time": "2020-12-23T03:13:35.162815Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./house_price_prediction_1.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./house_price_prediction_1.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们称这样的学习为监督学习。称其为监督式的学习，因为我们预先给了算法“正确结果”— —即所有我们观察到的变量。 \n",
    "上面这个问题又称为回归问题（Regression），因为我们能预测的结果是连续地值。 \n",
    "\n",
    "再来看另外一个问题：\n",
    "\n",
    "假使你希望预测一个乳腺癌是否是恶性的，你现在有的数据是不同年龄的病人和她们身上肿瘤的尺寸以及这些肿瘤是否是恶性的。如果我们将这些信息绘制成一张 2D 图表，以横坐标为肿瘤的尺寸，以纵坐标为病人的年龄，以 O 代表良性肿瘤，以 X 代表恶性肿瘤。则我们的算法要学习的问题就变成了如何分割良性肿瘤和恶性肿瘤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T03:19:16.452347Z",
     "start_time": "2020-12-23T03:19:16.444393Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./tumor_prediction.png\", width=500, heigth=100>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./tumor_prediction.png\", width=500, heigth=100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样的问题是分类问题（Classification），我们希望算法能够学会如何将数据分类到不同的类里。 \n",
    "### 非监督学习（Unsupervised Learning）\n",
    "在监督学习中，无论是回归问题还是分类问题，我们的数据都具有一个结果（房价问题中的房价，肿瘤问题中的良性与否）。  \n",
    "而在非监督学中，我们的现有数据中并没有结果，我们有的只是特征，因而非监督学习要解决的问题是发现这些数据是否可以分为不同的组。 \n",
    "非监督学习的一个例子是聚类问题（Clustering），例如鸢尾花iris数据集中，根据花萼的长度、宽度以及花瓣的长度、宽度将花聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多变量线性回归\n",
    "现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为（x1,x2,...,xn）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T01:55:31.117699Z",
     "start_time": "2020-12-24T01:55:31.109328Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./house_price_prediction_2.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./house_price_prediction_2.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型表达\n",
    "我们将要用来描述这个回归问题的标记如下:\n",
    "\n",
    "+ m 代表训练集中实例的数量\n",
    "+ x 代表特征/输入变量\n",
    "+ x(i)代表第 i 个训练实例，是特征矩阵中的第 i 行，是一个向量（vector）。\n",
    "+ x_{j}^{i}代表特征矩阵中第 i 行的第 j 个特征，也就是第 i 个训练实例的第 j 个特征。\n",
    "+ y 代表目标变量/输出变量\n",
    "+ (x,y) 代表训练集中的实例\n",
    "+ (x(i),y(i) ) 代表第 i 个观察实例\n",
    "+ h 代表学习算法的解决方案或函数也称为假设（hypothesis）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:09:46.457652Z",
     "start_time": "2020-12-24T02:09:46.448816Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./ml_process.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./ml_process.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持多变量的假设 h 表示为：\n",
    "\n",
    "$$h_{\\theta }(x)=\\theta _{0}+\\theta _{1}x_{1}+\\theta _{2}x_{2}+...+\\theta _{n}x_{n}$$\n",
    "\n",
    "这个公式中有 n+1 个参数和 n 个变量，为了使得公式能够简化一些，引入 x0=1，则公式转化为：\n",
    "\n",
    "$$h_{\\theta }(x)=\\theta _{0}x_{0}+\\theta _{1}x_{1}+\\theta _{2}x_{2}+...+\\theta _{n}x_{n}$$\n",
    "\n",
    "此时模型中的参数是一个 n+1 维的向量，任何一个训练实例也都是 n+1 维的向量，特征矩阵X 的维度是 m*n+1。 \n",
    "因此公式可以简化为：\n",
    "\n",
    "$$h_{\\theta }(x)=\\theta ^{T}x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "我们现在要做的便是为我们的模型选择合适的参数（parameters）$\\theta$。我们选择的参数决定了我们得到的预测结果相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T02:41:26.375449Z",
     "start_time": "2020-12-24T02:41:26.366382Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./modeling_error.png\", width=400, heigth=200>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./modeling_error.png\", width=400, heigth=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。\n",
    "即使得损失函数（Cost Function）:  \n",
    "\n",
    "$$J(\\theta _{0},\\theta _{1},...,\\theta _{n})=\\frac{1}{2m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$$\n",
    "    最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降(GRADIENT DESCENT)\n",
    "梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出损失函数 $J(\\theta _{0},\\theta _{1},...,\\theta _{n})$的最小值。梯度下降背后的思想是：开始时我们随机选择一个参数的组合$(\\theta _{0},\\theta _{1},...,\\theta _{n})$，计算损失函数，然后我们寻找下一个能让损失函数值下降最多的参数组合。我们持续这么做直到到到一个**局部最小值（local minimum）**,因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是**全局最小值（global minimum）**,选择不同的初始参数组合，可能会找到不同的局部最小值。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T03:09:28.028788Z",
     "start_time": "2020-12-24T03:09:28.023981Z"
    }
   },
   "source": [
    "### 梯度下降求解过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T03:09:08.044981Z",
     "start_time": "2020-12-24T03:09:08.037624Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./gradient_decent_1.jpg\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./gradient_decent_1.jpg\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批量梯度下降（batch gradient descent）算法的公式为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T03:13:35.820157Z",
     "start_time": "2020-12-24T03:13:35.812145Z"
    }
   },
   "source": [
    "repeat until convergence { \n",
    "\n",
    "$\\theta _{j}:=\\theta _{j}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})\\cdot x_{j}^{(i)}$  \n",
    "\n",
    "for j=(0,1,...,n)\n",
    "\n",
    "}  其中$\\alpha$为学习率\n",
    "\n",
    "我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T05:25:33.623935Z",
     "start_time": "2020-12-24T05:25:33.619249Z"
    }
   },
   "source": [
    "### 学习率\n",
    "梯度下降算法的每次迭代受到学习率的影响，如果学习率α过小，则达到收敛所需的迭代次数会非常高；如果学习率α过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。\n",
    "\n",
    "优化方法：\n",
    "+ SGD\n",
    "+ Adagrad\n",
    "+ RMSprop\n",
    "+ Adam\n",
    "......\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估\n",
    "## 分类器性能评估\n",
    "针对二分类问题\n",
    "\n",
    "四个概念：TP，FP，TN，FN\n",
    "\n",
    "+ TP（True Positive）：在判定为positive的样本中，判断正确的数目。\n",
    "\n",
    "+ FP（False Positive）：在判定为positive的样本中，判断错误的数目。\n",
    "\n",
    "+ TN（True Negative）：在判定为negative的样本中，判断正确的数目。\n",
    "\n",
    "+ FN（False Negative）：在判定为negative的样本中，判断错误的数目。\n",
    "\n",
    "\n",
    "\n",
    "计算 precision，recall，accuracy，F1 score\n",
    "\n",
    "+ 精确率（precision）：TP / (TP + FP)   预测为正的样本中实际正样本的比例\n",
    "\n",
    "+ 召回率（recall）：TP / (TP + FN)  实际正样本中预测为正的比例\n",
    " \n",
    "+ 准确率（accuracy）： (TP + TN) / (P + N)\n",
    "\n",
    "可见，精确率和召回率是相互影响的，理想情况下两者都高，但是一般情况下准确率高，召回率就低；召回率高，准确率就低；如果两者都低，模型有问题。\n",
    "\n",
    "在两者都要求高的情况下，综合衡量P和R就用F值：\n",
    "\n",
    "+ F1-score = 2 / [(1 / precision) + (1 / recall)]\n",
    "\n",
    "\n",
    "一般多个模型假设进行比较时，F1 score越高，说明它越好。\n",
    "\n",
    "+ 混淆矩阵 confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T05:57:53.277412Z",
     "start_time": "2020-12-25T05:57:53.268822Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./Flow_ConfusionMatrix.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./Flow_ConfusionMatrix.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **真正例率（Ture positive rare）**，TPR=TP/(TP+FN）ROC曲线的纵轴  表示当前分到正样本中真实的正样本所占所有正样本的比例；\n",
    "+ **假正例率（False positive rare）**，FPR=FP/(TN+FP) ROC曲线的横轴  表示当前被错误分到正样本类别中的负样本,所占所有负样本总数的比例；\n",
    "+ **ROC曲线（ROC curve）**                                   \n",
    "对于ROC来说，横坐标就是FPR，而纵坐标就是TPR，因此可以想见，当 TPR越大，而FPR越小时，说明分类结果是较好的。 \n",
    "ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。\n",
    "比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=0，对应于右上角的点(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T06:24:16.511759Z",
     "start_time": "2020-12-25T06:24:16.503133Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./roc_curve.png\", width=800, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./roc_curve.png\", width=800, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **AUC** ROC曲线下方的面积大小\n",
    "AUC 是用来评估把正样本概率排到前面的能力,AUC越接近1，算法越准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **logloss** 损失函数 ，越小越好 反映的是样本预测概率的准确性\n",
    "$$LogLoss=-\\frac{1}{n}\\sum_{i}^{N}(y_{i}log{p_{i}}+(1-y_{i})log(1-{p_{i})})$$\n",
    "\n",
    "比如 1 1 0 1 ,预测值 为 0.5 0.5 0.3 0.5 那么 auc 是 1 \n",
    "\n",
    "我们提升预测值到 0.7 0.7 0.4 0.7 ,那么 auc 依然是1,但是 logloss 有了很大的提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归性能评估\n",
    "+ **均方误差 mse**  \n",
    "$$\\frac{1}{m}\\sum_{i=1}^{m}(y_{i}-\\widehat{y_{i}})^{2}$$\n",
    "+ **均方根误差rmse**\n",
    "$$\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(y_{i}-\\widehat{y_{i}})^{2}}$$\n",
    "+ **平均绝对误差mae**\n",
    "$$\\frac{1}{m}\\sum_{i=1}^{m}\\left | (y_{i}-\\widehat{y_{i}}) \\right |$$\n",
    "+ **R-Squared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T07:29:16.062662Z",
     "start_time": "2020-12-25T07:29:16.050334Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./R2.png\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./R2.png\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T07:31:19.942159Z",
     "start_time": "2020-12-25T07:31:19.933140Z"
    }
   },
   "source": [
    "分子：预测值-实际值，our model，分母：平均值-实际值，baseline model）\n",
    "\n",
    "使用baseline模型肯定会产生很多错误，我们自己的模型产生的错误会少一些。\n",
    "\n",
    "1 - ourModelError / baselineModelError = 我们模型拟合住的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  特征工程（Feature Engineering）\n",
    "数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。\n",
    "特征工程是利用数据领域的相关知识来创建能够使机器学习算法达到最佳性能的特征的过程。 \n",
    "\n",
    "简而言之，特征工程就是一个把原始数据转变成特征的过程，这些特征可以很好的描述这些数据，并且利用它们建立的模型在未知数据上的表现性能可以达到最优（或者接近最佳性能）。从数学的角度来看，特征工程就是人工地去设计输入变量X。 \n",
    "\n",
    "Feature Engineering!=Feature selection\n",
    "\n",
    "## 特征工程子问题\n",
    "大家通常会把特征工程看做是一个问题。事实上，在特征工程下面，还有许多的子问题，主要包括： \n",
    "+ Feature Extraction（特征提取）\n",
    "+ **Feature construction（特征构造）**\n",
    "+ Feature Selection（特征选择）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T09:09:49.379891Z",
     "start_time": "2020-12-24T09:09:49.371023Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./feature_engineering.jpg\", width=600, heigth=400>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./feature_engineering.jpg\", width=600, heigth=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用场景"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
